#!/usr/bin/env python
# +-----------------------------------------------------------------+
# |                                                                 |
# |        (  ___ \     | \    /\|\     /||\     /|( (    /|        |
# |        | (   ) )    |  \  / /| )   ( || )   ( ||  \  ( |        |
# |        | (__/ /     |  (_/ / | |   | || (___) ||   \ | |        |
# |        |  __ (      |   _ (  | |   | ||  ___  || (\ \) |        |
# |        | (  \ \     |  ( \ \ | |   | || (   ) || | \   |        |
# |        | )___) )_   |  /  \ \| (___) || )   ( || )  \  |        |
# |        |/ \___/(_)  |_/    \/(_______)|/     \||/    )_)        |
# |                                                                 |
# | Copyright Bastian Kuhn 2018                mail@bastian-kuhn.de |
# +-----------------------------------------------------------------+
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

"""
Agent Exasol
"""
import sys
import ssl
import json
import time
import os
from xmlrpclib import ServerProxy
from urllib import quote_plus

CONFIG = {
    "hostname" : sys.argv[1],
    "user_name" : quote_plus(sys.argv[2]),
    "user_password" : quote_plus(sys.argv[3]),
}

CACHE_FILE = os.path.expanduser("~/tmp/check_mk/exasol_"+CONFIG['hostname'])
CACHE_DURCATION = 3600

def xml_rpc(path):
    """
    XML RPC Helper
    """
    params = CONFIG
    params['path'] = path
    url = 'https://{user_name}:{user_password}@{hostname}/cluster1{path}'.format(**params)
    if hasattr(ssl, 'SSLContext'):
        sslcontext = ssl.SSLContext(ssl.PROTOCOL_TLS)
        sslcontext.verify_mode = ssl.CERT_NONE
        sslcontext.check_hostname = False
        return ServerProxy(url, context=sslcontext)
    return ServerProxy(url)


CLUSTER = xml_rpc('/')
STORAGE = xml_rpc('/storage')

print "<<<exasol_nodes>>>"
for node in CLUSTER.getNodeList():
    node_info = CLUSTER.getNodeState(node)
    print "{0} {1}".format(node, node_info['status'])

print "<<<exasol_services>>>"
for module, state in CLUSTER.getServiceState():
    print "{0} {1}".format(module, state)

print "<<<exasol_database>>>"
for database_name in CLUSTER.getDatabaseList():
    database = xml_rpc('/db_' + quote_plus(database_name))
    db_info = database.getDatabaseInfo()
    print "[[[{0}]]]".format(db_info['name'])

    db_nodes = db_info['nodes']['active']
    db_volume = db_info['persistent volume']
    db_tmp_volume = db_info['temporary volume']

    db_segments = []
    db_volume_info = STORAGE.getVolumeInfo(db_volume)

    for red_layer in range(0, db_volume_info['redundancy']):
        db_segments += db_volume_info['segments'][red_layer]

    db_tmp_volume_info = STORAGE.getVolumeInfo(db_tmp_volume)
    db_tmp_segments = db_tmp_volume_info['segments'][0]

    databaseSegmentUsage = (db_info['usage persistent'] / float(len(db_segments)))* \
                                                            db_volume_info['redundancy']
    databaseTempSegmentUsage = (db_info['usage temporary']/ float(len(db_tmp_segments)))

    partion_sizes = {}
    if os.path.isfile(CACHE_FILE) and \
        time.time() - os.path.getctime(CACHE_FILE) < CACHE_DURCATION:
        with open(CACHE_FILE, 'r') as f:
            partion_sizes = json.load(f)
    else:
        for node in sorted(set(db_segments)):
            partitions = xml_rpc('/' + node).getDiskStates()
            for partition in partitions:
                if partition['name'] == db_volume_info['disk']:
                    size = float(partition['size'])
                    partion_sizes[node] = size
            with open(CACHE_FILE, 'w') as f:
                json.dump(partion_sizes, f, separators=(',', ':'))

    for volume in STORAGE.getVolumeList():
        if volume.startswith('v') and volume not in [db_volume, db_tmp_volume]:
            volumeInfo = STORAGE.getVolumeInfo(volume)
            volumeSizePerNode = (volumeInfo['size'] / float(len(volumeInfo['segments'][0])))

            segments = []
            for red_layer in range(0, volumeInfo['redundancy']):
                segments += volumeInfo['segments'][red_layer]

            for node in segments:
                if node in partion_sizes.keys():
                    partion_sizes[node] -= volumeSizePerNode

        elif volume == db_volume:
            for node in db_segments:
                partion_sizes[node] -= databaseSegmentUsage

        elif volume == db_tmp_volume:
            for node in db_tmp_segments:
                partion_sizes[node] -= databaseTempSegmentUsage


    minPartitionSize = None
    minPartitionNode = ''
    for node in partion_sizes:
        if not minPartitionSize or partion_sizes[node] < minPartitionSize:
            minPartitionSize = partion_sizes[node]
            minPartitionNode = node


    usedSegmentSpace = ((databaseSegmentUsage * db_segments.count(minPartitionNode)) +
                        databaseTempSegmentUsage)

    print "usage "+ str(usedSegmentSpace)
    print "free "+ str(minPartitionSize)
    backup_cache = CACHE_FILE + "_backup"
    backups = []
    if os.path.isfile(backup_cache) and \
        time.time() - os.path.getctime(CACHE_FILE) < CACHE_DURCATION:
        with open(backup_cache, 'r') as f:
            backups = json.load(f)
    else:
        backup_list = database.getBackupList()
        r_found = False
        v_found = False
        for backup in reversed(backup_list):
            backupInfo = database.getBackupInfo(backup[0])
            if backupInfo['usable']:
                volume = backupInfo['volume'][0]
                for backupId in backupInfo['dependencies']:
                    backups.append(database.getBackupInfo((backupId, volume)))
                backups.append(backupInfo)
                break
        with open(backup_cache, 'w') as f:
            json.dump(backups, f, separators=(',', ':'))


    for backup in backups:
        print "backup_expiration " +  backup['expire date']

